{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import math, copy, time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "from skeleton_models import ntu_rgbd, ntu_ss_1, ntu_ss_2, ntu_ss_3\n",
    "from graph import Graph\n",
    "from render import animate, save_animation\n",
    "from datasets import NTUDataset, Normalize, CropSequence, SelectDimensions, SelectSubSample\n",
    "\n",
    "# Model components\n",
    "from zoo_pose_embedding import TwoLayersGCNPoseEmbedding, JoaosDownsampling, SuperSimpleDownsampling\n",
    "from zoo_action_encoder_units import TransformerEncoderUnit\n",
    "from zoo_action_decoder_units import TransformerDecoderUnit\n",
    "from zoo_upsampling import StepByStepUpsampling, JoaosUpsampling, SuperSimpleUpsampling\n",
    "from model import ActionEmbeddingTransformer, SimplePoseEncoderDecoder\n",
    "from layers import subsequent_mask\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "Warn: not activated\n",
      "Warn: not activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.7442:   0%|          | 0/200000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss = 0.7442317008972168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0718:   0%|          | 250/200000 [08:02<105:00:57,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 loss = 0.07176075875759125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0636:   0%|          | 500/200000 [15:46<92:26:20,  1.67s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 loss = 0.06359687447547913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0554:   0%|          | 750/200000 [23:00<88:48:05,  1.60s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 750 loss = 0.05539754405617714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0582:   0%|          | 1000/200000 [30:10<89:52:08,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 loss = 0.058163076639175415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0540:   1%|          | 1250/200000 [37:27<101:33:54,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1250 loss = 0.054011598229408264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0514:   1%|          | 1500/200000 [44:58<92:35:24,  1.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500 loss = 0.051385171711444855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0493:   1%|          | 1750/200000 [52:49<98:11:35,  1.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1750 loss = 0.04931965097784996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0485:   1%|          | 2000/200000 [1:01:18<133:39:06,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000 loss = 0.048507824540138245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0474:   1%|          | 2250/200000 [1:09:07<89:17:19,  1.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2250 loss = 0.04742930829524994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0466:   1%|▏         | 2500/200000 [1:17:02<105:07:20,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2500 loss = 0.04655918478965759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0460:   1%|▏         | 2750/200000 [1:25:01<104:01:44,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2750 loss = 0.04595132917165756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0455:   2%|▏         | 3000/200000 [1:32:45<88:58:17,  1.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000 loss = 0.04553656280040741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0469:   2%|▏         | 3250/200000 [1:40:20<88:26:35,  1.62s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3250 loss = 0.046893153339624405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0472:   2%|▏         | 3500/200000 [1:47:43<91:31:30,  1.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3500 loss = 0.04722341150045395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0439:   2%|▏         | 3750/200000 [1:54:58<87:25:09,  1.60s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3750 loss = 0.04394150152802467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0432:   2%|▏         | 4000/200000 [2:02:06<89:41:40,  1.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000 loss = 0.0432048998773098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0420:   2%|▏         | 4250/200000 [2:09:10<87:25:24,  1.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4250 loss = 0.04196389764547348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0458:   2%|▏         | 4500/200000 [2:16:14<86:41:56,  1.60s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4500 loss = 0.04583263024687767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0446:   2%|▏         | 4750/200000 [2:23:16<86:59:33,  1.60s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4750 loss = 0.04458450525999069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0433:   2%|▎         | 5000/200000 [2:30:20<87:12:35,  1.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5000 loss = 0.04333155229687691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0401:   3%|▎         | 5250/200000 [2:37:23<87:23:09,  1.62s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5250 loss = 0.040099408477544785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0404:   3%|▎         | 5500/200000 [2:44:25<87:09:52,  1.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5500 loss = 0.04038780555129051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0332:   3%|▎         | 5750/200000 [2:51:23<84:52:48,  1.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5750 loss = 0.03322248160839081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0265:   3%|▎         | 6000/200000 [2:58:16<84:40:11,  1.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6000 loss = 0.02651612088084221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0248:   3%|▎         | 6250/200000 [3:05:09<85:43:56,  1.59s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6250 loss = 0.024833746254444122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0242:   3%|▎         | 6500/200000 [3:12:02<83:59:37,  1.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6500 loss = 0.02421506866812706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0304:   3%|▎         | 6750/200000 [3:18:55<84:27:14,  1.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6750 loss = 0.030377520248293877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0300:   4%|▎         | 7000/200000 [3:25:47<88:18:17,  1.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7000 loss = 0.029960719868540764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0283:   4%|▎         | 7250/200000 [3:32:38<85:12:04,  1.59s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7250 loss = 0.028275303542613983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0274:   4%|▍         | 7500/200000 [3:39:31<84:31:50,  1.58s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7500 loss = 0.02736840397119522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0263:   4%|▍         | 7750/200000 [3:46:25<83:57:48,  1.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7750 loss = 0.026272529736161232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Curr loss = 0.0245:   4%|▍         | 7908/200000 [3:51:12<93:36:24,  1.75s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a6fd32f267fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Curr loss = {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hielo/application/anaconda/envs/cv/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hielo/application/anaconda/envs/cv/lib/python3.8/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    110\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skeleton_model = ntu_rgbd\n",
    "adjacency = Graph(skeleton_model)\n",
    "conf_kernel_size = adjacency.A.shape[0]\n",
    "conf_num_nodes = adjacency.A.shape[1]\n",
    "conf_heads = 5\n",
    "conf_encoding_per_node = 100\n",
    "conf_internal_per_node = int(conf_encoding_per_node/conf_heads)\n",
    "print(conf_encoding_per_node*conf_num_nodes)\n",
    "\n",
    "\n",
    "class BetterThatBestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = ActionEmbeddingTransformer(\n",
    "            JoaosDownsampling(\n",
    "                conf_num_nodes,\n",
    "                conf_encoding_per_node*conf_num_nodes,\n",
    "                node_channel_in = 2,\n",
    "                device=device\n",
    "            ),\n",
    "            TransformerEncoderUnit (\n",
    "                heads=conf_heads,\n",
    "                embedding_in=conf_num_nodes*conf_encoding_per_node,\n",
    "                embedding_out=conf_num_nodes*conf_internal_per_node\n",
    "            ),\n",
    "            TransformerDecoderUnit(\n",
    "                heads=conf_heads,\n",
    "                embedding_in=conf_num_nodes*conf_encoding_per_node,\n",
    "                embedding_out=conf_num_nodes*conf_internal_per_node,\n",
    "                memory_in=conf_num_nodes*conf_encoding_per_node\n",
    "            ),\n",
    "            JoaosUpsampling(\n",
    "                conf_num_nodes,\n",
    "                conf_encoding_per_node*conf_num_nodes,\n",
    "                node_channel_out = 2,\n",
    "                device=device\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x_in, x_out, A, mask):\n",
    "        return self.model(x_in, x_out, A, mask)\n",
    "    \n",
    "model = BetterThatBestModel()\n",
    "\n",
    "A = torch.from_numpy(adjacency.A).to(device, dtype=torch.float)\n",
    "model = model.to(device)\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "composed = transforms.Compose([Normalize(),\n",
    "                               SelectDimensions(2),\n",
    "                               SelectSubSample(skeleton_model)\n",
    "                              ])\n",
    "\n",
    "#ntu_dataset = NTUDataset(root_dir='../ntu-rgbd-dataset/Python/raw_npy/')\n",
    "ntu_dataset = NTUDataset(root_dir='../datasets/NTURGB-D/Python/sel_npy/', transform=composed)\n",
    "loader = DataLoader(ntu_dataset, batch_size=512, shuffle=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2)\n",
    "\n",
    "\n",
    "pbar = tqdm(range(200000), desc='Initializing ...')\n",
    "for epoch in pbar:\n",
    "    \n",
    "    for data in loader:\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        \n",
    "        n_out, t_out, v_out, c_out = data.size()\n",
    "        mask = subsequent_mask(t_out).to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data, data, A, mask)\n",
    "\n",
    "        loss = criterion(out, data)\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        pbar.set_description(\"Curr loss = {:.4f}\".format(loss.item()))\n",
    "        \n",
    "    if epoch == 0:\n",
    "        save_animation(data[0], skeleton_model, 'outputs/animations/a_sample_example_epoch_{}.gif'.format(epoch))\n",
    "    \n",
    "    if epoch % 250 == 0:\n",
    "        print('Epoch {} loss = {}'.format(epoch, loss.item()))\n",
    "        # torch.save(model.state_dict(), 'outputs/models/simple_encoder_epoch_{}.pth'.format(epoch))\n",
    "        # save_animation(data[0], ntu_rgbd, 'outputs/animations/sample_example_epoch_{}.gif'.format(epoch))\n",
    "        save_animation(out[0], skeleton_model, 'outputs/animations/out_example_epoch_{}.gif'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_model = ntu_rgbd\n",
    "adjacency = Graph(skeleton_model)\n",
    "conf_kernel_size = adjacency.A.shape[0]\n",
    "conf_num_nodes = adjacency.A.shape[1]\n",
    "conf_heads = 5\n",
    "conf_encoding_per_node = 100\n",
    "conf_internal_per_node = int(conf_encoding_per_node/conf_heads)\n",
    "print(conf_encoding_per_node*conf_num_nodes)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using {}'.format(device))\n",
    "\n",
    "model = SimplePoseEncoderDecoder(\n",
    "    JoaosDownsampling(\n",
    "        conf_num_nodes,\n",
    "        conf_encoding_per_node*conf_num_nodes,\n",
    "        node_channel_in = 2,\n",
    "        device=device\n",
    "    ),\n",
    "    JoaosUpsampling(\n",
    "        conf_num_nodes,\n",
    "        conf_encoding_per_node*conf_num_nodes,\n",
    "        node_channel_out = 2,\n",
    "        device=device\n",
    "    )\n",
    ")\n",
    "\n",
    "A = torch.from_numpy(adjacency.A).to(device, dtype=torch.float)\n",
    "model = model.to(device)\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "composed = transforms.Compose([Normalize(),\n",
    "                               SelectDimensions(2),\n",
    "                               SelectSubSample(skeleton_model)\n",
    "                              ])\n",
    "\n",
    "#ntu_dataset = NTUDataset(root_dir='../ntu-rgbd-dataset/Python/raw_npy/')\n",
    "ntu_dataset = NTUDataset(root_dir='../datasets/NTURGB-D/Python/sel_npy/', transform=composed)\n",
    "loader = DataLoader(ntu_dataset, batch_size=512, shuffle=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2)\n",
    "\n",
    "\n",
    "pbar = tqdm(range(200000), desc='Initializing ...')\n",
    "for epoch in pbar:\n",
    "    \n",
    "    for data in loader:\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "\n",
    "        n_out, c_out, t_out, v_out = data.size()\n",
    "        mask = subsequent_mask(t_out).to(device, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data, A)\n",
    "\n",
    "        loss = criterion(out, data)\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        pbar.set_description(\"Curr loss = {:.4f}\".format(loss.item()))\n",
    "        \n",
    "    if epoch == 0:\n",
    "        save_animation(data[0], skeleton_model, 'outputs/animations/a_sample_example_epoch_{}.gif'.format(epoch))\n",
    "    \n",
    "    if epoch % 3000 == 0:\n",
    "        print('Epoch {} loss = {}'.format(epoch, loss.item()))\n",
    "        # torch.save(model.state_dict(), 'outputs/models/simple_encoder_epoch_{}.pth'.format(epoch))\n",
    "        # save_animation(data[0], ntu_rgbd, 'outputs/animations/sample_example_epoch_{}.gif'.format(epoch))\n",
    "        save_animation(out[0], skeleton_model, 'outputs/animations/out_example_epoch_{}.gif'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ntu_dataset[0][:,:,1].min())\n",
    "print(ntu_dataset[0][:,:,0].min())\n",
    "print(ntu_dataset[0][:,:,1].max())\n",
    "print(ntu_dataset[0][:,:,0].max())\n",
    "print(ntu_dataset[0][:,:,1].mean())\n",
    "print(ntu_dataset[0][:,:,0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ntu_dataset[0]\n",
    "a[:,:,0] = a[:,:,0] - a[:,:,0].min()\n",
    "a[:,:,1] = a[:,:,1] - a[:,:,1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntu_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[:,:,1].min())\n",
    "print(a[:,:,0].min())\n",
    "print(a[:,:,1].max())\n",
    "print(a[:,:,0].max())\n",
    "print(a[:,:,1].mean())\n",
    "print(a[:,:,0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
